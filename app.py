# app.py â€”â€” åªè¯» CSV çš„ Streamlit çœ‹æ¿ï¼ˆæ— å¤–éƒ¨ API è°ƒç”¨ï¼‰
import os
from datetime import date

import altair as alt
import pandas as pd
import streamlit as st

st.set_page_config(page_title="YouTube Tracker", layout="wide")

# å¯é€‰ï¼šé¡µé¢è‡ªåŠ¨åˆ·æ–°
try:
    from streamlit_autorefresh import st_autorefresh
    st_autorefresh(interval=5 * 60 * 1000, key="auto-refresh")
except Exception:
    pass

# ---- å°æ ·å¼ ----
st.markdown(
    """
<style>
.thumb-cell { display: flex; align-items: center; height: 100%; }
.thumb-cell img { max-width: 100%; }
</style>
""",
    unsafe_allow_html=True,
)

@st.cache_data(ttl=300)
def load_data():
    df = pd.read_csv("data/history.csv")
    df["date"] = pd.to_datetime(df["date"], errors="coerce", utc=True)
    df["published_at"] = pd.to_datetime(df["published_at"], errors="coerce", utc=True)
    return df

def days_since(d):
    if pd.isna(d):
        return None
    if getattr(d, "tzinfo", None) is None:
        d_utc = d.tz_localize("UTC")
    else:
        d_utc = d.tz_convert("UTC")
    now_utc = pd.Timestamp.now(tz="UTC")
    return (now_utc - d_utc).days

df = load_data()
df["day"] = df["date"].dt.date   # âœ… æ–°å¢çº¯æ—¥æœŸåˆ—

st.title("ğŸ“ˆ YouTube è§†é¢‘è¿½è¸ªé¢æ¿")

if df.empty:
    st.info("æš‚æ— æ•°æ®ï¼Œè¯·å…ˆç¡®ä¿ä»“åº“ä¸­çš„ data/history.csv å·²æœ‰å†…å®¹ã€‚")
    st.stop()

# ==== æ•°æ®æœ€åæ›´æ–°æ—¶é—´ ====
csv_last_ts = pd.to_datetime(df["date"], errors="coerce").max()
last_file_time_la = None
try:
    mtime = os.path.getmtime("data/history.csv")
    last_file_time_la = (
        pd.to_datetime(mtime, unit="s", utc=True)
        .tz_convert("America/Los_Angeles")
        .strftime("%Y-%m-%d %H:%M:%S %Z")
    )
except Exception:
    pass

msg_left = (
    f"CSV æœ€æ–°æ—¥æœŸï¼š**{csv_last_ts.tz_convert('UTC').date().isoformat()}**"
    if pd.notna(csv_last_ts) else "CSV æœ€æ–°æ—¥æœŸï¼š**æœªçŸ¥**"
)
msg_right = f"ï½œ æ–‡ä»¶æ›´æ–°æ—¶é—´ï¼ˆLAï¼‰ï¼š**{last_file_time_la}**" if last_file_time_la else ""
st.info(f"ğŸ•’ {msg_left} {msg_right}")

# ==== æœ€æ–°ä¸€è¡Œ ====
latest = df.sort_values("date").groupby("video_id").tail(1).copy()
latest = latest.sort_values("published_at", ascending=False, na_position="last")

# -------- ä¾§è¾¹ç­›é€‰ --------
with st.sidebar:
    st.header("ç­›é€‰ & å·¥å…·")

    channels = sorted(latest["channel_title"].dropna().unique().tolist())
    channel_options = ["All"] + channels
    sel_channel = st.selectbox("æŒ‰é¢‘é“ç­›é€‰", channel_options, index=0)

    metric_label = st.selectbox(
        "æŠ˜çº¿å›¾æŒ‡æ ‡", ["æ’­æ”¾é‡ (Views)", "ç‚¹èµæ•° (Likes)", "è¯„è®ºæ•° (Comments)"], index=0
    )
    metric_map = {
        "æ’­æ”¾é‡ (Views)": ("views", "æ’­æ”¾é‡"),
        "ç‚¹èµæ•° (Likes)": ("likes", "ç‚¹èµæ•°"),
        "è¯„è®ºæ•° (Comments)": ("comments", "è¯„è®ºæ•°"),
    }
    metric_col, metric_cn = metric_map[metric_label]

    mode = st.radio("æ•°å€¼æ¨¡å¼", ["ç´¯è®¡", "æ¯æ—¥å¢é‡"], index=0, horizontal=True)

    min_d = df["day"].min()
    max_d = df["day"].max()
    picked = st.date_input("æŠ˜çº¿å›¾æ—¥æœŸèŒƒå›´", [min_d, max_d])
    if isinstance(picked, list) and len(picked) == 2:
        start_day, end_day = picked
    else:
        start_day, end_day = (min_d, max_d)

    sort_label = st.selectbox(
        "æ’åºä¾æ®", ["æŒ‰æ’­æ”¾é‡", "æŒ‰ç‚¹èµæ•°", "æŒ‰è¯„è®ºæ•°", "æŒ‰å‘å¸ƒæ—¥æœŸï¼ˆæ–°â†’æ—§ï¼‰"], index=3
    )
    sort_map = {"æŒ‰æ’­æ”¾é‡": "views", "æŒ‰ç‚¹èµæ•°": "likes", "æŒ‰è¯„è®ºæ•°": "comments"}

    st.write("---")
    if st.button("ğŸ”„ åˆ·æ–°æ•°æ®ï¼ˆæ¸…ç¼“å­˜ï¼‰", key="refresh"):
        st.cache_data.clear()
        st.rerun()

filtered_latest = (
    latest if sel_channel == "All" else latest[latest["channel_title"] == sel_channel]
)

if sort_label == "æŒ‰å‘å¸ƒæ—¥æœŸï¼ˆæ–°â†’æ—§ï¼‰":
    filtered_latest = filtered_latest.sort_values(
        "published_at", ascending=False, na_position="last"
    )
else:
    sort_col = sort_map[sort_label]
    filtered_latest = filtered_latest.sort_values(sort_col, ascending=False)

selected_ids = set(filtered_latest["video_id"].tolist())

# ==== æ—¥æœŸèŒƒå›´è¿‡æ»¤ ====
show_df = df[df["video_id"].isin(selected_ids)].copy()
show_df_for_chart = show_df[
    (show_df["day"] >= start_day) & (show_df["day"] <= end_day)
].copy()

# ==== Debug è¾“å‡º ====
st.info(f"ğŸ” Debug: å½“å‰é€‰æ‹©æ—¥æœŸèŒƒå›´ = {start_day} â†’ {end_day} ï½œ show_df_for_chart è¡Œæ•° = {show_df_for_chart.shape[0]}")

# ==== KPI è®¡ç®— ====
base = df[df["video_id"].isin(selected_ids)].sort_values(["video_id", "date"]).copy()
for col in ["views", "likes", "comments"]:
    inc_col = f"{col}_inc"
    base[inc_col] = base.groupby("video_id")[col].diff().fillna(0)
    base.loc[base[inc_col] < 0, inc_col] = 0

interval_df = base[(base["day"] >= start_day) & (base["day"] <= end_day)].copy()

iv_views = int(interval_df["views_inc"].sum()) if not interval_df.empty else 0
iv_likes = int(interval_df["likes_inc"].sum()) if not interval_df.empty else 0
iv_comments = int(interval_df["comments_inc"].sum()) if not interval_df.empty else 0

i1, i2, i3 = st.columns(3)
i1.metric("æœ¬æœŸæ€»å¢é‡ Â· æ’­æ”¾é‡", f"{iv_views:,}")
i2.metric("æœ¬æœŸæ€»å¢é‡ Â· ç‚¹èµæ•°", f"{iv_likes:,}")
i3.metric("æœ¬æœŸæ€»å¢é‡ Â· è¯„è®ºæ•°", f"{iv_comments:,}")

# ====== å•è§†é¢‘æŠ˜çº¿ ======
for _, row in filtered_latest.iterrows():
    vid = row["video_id"]
    col1, col2 = st.columns([1, 3])
    with col1:
        thumb = row.get("thumbnail_url", None)
        st.markdown("<div class='thumb-cell'>", unsafe_allow_html=True)
        if pd.notna(thumb) and thumb:
            st.image(thumb, use_container_width=True)
        st.markdown("</div>", unsafe_allow_html=True)
        st.markdown(f"[â–¶ï¸ æ‰“å¼€è§†é¢‘]({row['video_url']})")
    with col2:
        st.subheader(f"{row['title']}")
        st.write(f"**é¢‘é“**ï¼š{row['channel_title']}")
        pub = row["published_at"]
        dcount = days_since(pub)
        pub_text = (
            pub.tz_convert("UTC").date().isoformat() if pd.notna(pub) else "æœªçŸ¥"
        )
        st.write(f"**å‘å¸ƒæ—¥æœŸ**ï¼š{pub_text} ï½œ **å·²å‘å¸ƒ**ï¼š{dcount} å¤©")
        c1, c2, c3 = st.columns(3)
        c1.metric("æ€»æ’­æ”¾é‡", f"{int(row['views']):,}")
        c2.metric("æ€»ç‚¹èµæ•°", f"{int(row['likes']):,}")
        c3.metric("æ€»è¯„è®ºæ•°", f"{int(row['comments']):,}")

        vhist = (
            show_df_for_chart[show_df_for_chart["video_id"] == vid]
            .sort_values("date").copy()
        )
        if vhist.empty:
            st.info("å½“å‰æ—¥æœŸèŒƒå›´å†…æ— æ•°æ®")
            continue

        if mode == "æ¯æ—¥å¢é‡":
            vhist["value"] = vhist[metric_col].diff().fillna(0)
            vhist.loc[vhist["value"] < 0, "value"] = 0
            y_title = f"{metric_cn}ï¼ˆæ¯æ—¥å¢é‡ï¼‰"
        else:
            vhist["value"] = vhist[metric_col]
            y_title = f"{metric_cn}ï¼ˆç´¯è®¡ï¼‰"

        base = alt.Chart(vhist).encode(
            x=alt.X("date:T", title="æ—¥æœŸ"),
            y=alt.Y("value:Q", title=y_title),
            tooltip=[
                alt.Tooltip("date:T", title="æ—¥æœŸ"),
                alt.Tooltip("value:Q", title=y_title, format=","),
            ],
        )
        chart = (base.mark_line() + base.mark_point(size=40) + 
                 base.mark_text(dy=-8).encode(text=alt.Text("value:Q", format=","))).properties(height=220)
        st.altair_chart(chart, use_container_width=True)

st.write("---")
st.caption("æ•°æ®æ¥æºï¼šdata/history.csvï¼ˆç”±å®šæ—¶ä»»åŠ¡æ›´æ–°ï¼‰ã€‚æ—¶åŒºï¼šAmerica/Los_Angelesã€‚")
