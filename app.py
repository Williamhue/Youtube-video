# app.py â€”â€” åªè¯» CSV çš„ Streamlit çœ‹æ¿ï¼ˆæ— å¤–éƒ¨ API è°ƒç”¨ï¼‰
import os
from datetime import date, timedelta
from io import BytesIO

import altair as alt
import pandas as pd
import streamlit as st

st.set_page_config(page_title="YouTube Tracker", layout="wide")

# å¯é€‰è‡ªåŠ¨åˆ·æ–°
try:
    from streamlit_autorefresh import st_autorefresh
    st_autorefresh(interval=5 * 60 * 1000, key="auto-refresh")
except Exception:
    pass

# ---- æ ·å¼ï¼šç¼©ç•¥å›¾å‚ç›´å±…ä¸­ ----
st.markdown(
    """
<style>
.thumb-cell { display: flex; align-items: center; height: 100%; }
.thumb-cell img { max-width: 100%; }
</style>
""",
    unsafe_allow_html=True,
)

# ====== å°å·¥å…· ======
def coerce_date_range(picked, fallback_start, fallback_end):
    """æŠŠ st.date_input è¿”å›å€¼è§„èŒƒä¸º (start_date, end_date)ï¼Œå‡ä¸º datetime.dateã€‚"""
    if isinstance(picked, (list, tuple)):
        if len(picked) == 2:
            s, e = picked
        elif len(picked) == 1:
            s, e = picked[0], picked[0]
        else:
            s, e = fallback_start, fallback_end
    else:
        s, e = picked, picked
    s = s or fallback_start
    e = e or fallback_end
    if s > e:
        s, e = e, s
    return s, e

def days_since(d):
    """å‘å¸ƒæ—¶é—´è·ä»Šå¤©æ•°ï¼›å…¼å®¹ tz-naive / tz-awareã€‚"""
    if pd.isna(d):
        return None
    if getattr(d, "tzinfo", None) is None:
        d_utc = d.tz_localize("UTC")
    else:
        d_utc = d.tz_convert("UTC")
    now_utc = pd.Timestamp.now(tz="UTC")
    return (now_utc - d_utc).days

# ====== è¯»æ•°ï¼ˆå¸¦æ¸…æ´—ï¼‰ ======
@st.cache_data(ttl=300)
def load_data():
    # è¯»å–å¹¶æ¸…ç† BOM
    with open("data/history.csv", "rb") as f:
        raw = f.read()
    if raw.startswith(b"\xef\xbb\xbf"):
        raw = raw[3:]
    df = pd.read_csv(BytesIO(raw))

    # åˆ—åä¸å­—ç¬¦ä¸²å»ç©ºç™½
    df.columns = df.columns.map(lambda c: str(c).strip())
    for col in df.columns:
        if df[col].dtype == object:
            df[col] = df[col].astype(str).str.strip()

    # å…³é”®æ—¶é—´åˆ—ï¼šç»Ÿä¸€ä¸º tz-aware UTC
    df["date"] = pd.to_datetime(df["date"], errors="coerce", utc=True)
    df["published_at"] = pd.to_datetime(df.get("published_at"), errors="coerce", utc=True)

    # æ–°å¢â€œè‡ªç„¶æ—¥â€åˆ—ï¼šå…¨éƒ¨é™ç»´åˆ° dateï¼ˆæ— æ—¶åŒºï¼‰ï¼Œæ‰€æœ‰è¿‡æ»¤éƒ½ç”¨å®ƒ
    df["day"] = df["date"].dt.date

    # è‹¥è§†é¢‘é“¾æ¥ç¼ºå¤±ï¼Œä½†æœ‰ video_idï¼Œå°±è¡¥å…¨ï¼ˆå¯é€‰ï¼‰
    if "video_url" in df.columns and "video_id" in df.columns:
        df["video_url"] = df["video_url"].where(df["video_url"].ne(""), "https://www.youtube.com/watch?v=" + df["video_id"])

    return df

# ====== ä¸»æµç¨‹ ======
df = load_data()

st.title("ğŸ“ˆ YouTube è§†é¢‘è¿½è¸ªé¢æ¿")

if df.empty or df["date"].isna().all() or df["day"].isna().all():
    st.error("æ— æ³•è§£æ data/history.csv çš„æ—¥æœŸåˆ—ã€‚è¯·æ£€æŸ¥æ˜¯å¦å­˜åœ¨éšè—ç©ºæ ¼/BOM æˆ–æ—¥æœŸæ ¼å¼å¼‚å¸¸ã€‚")
    st.stop()

# ==== æ•°æ®æœ€åæ›´æ–°æ—¶é—´ï¼ˆåŸºäº CSV å†…å®¹ + æ–‡ä»¶å†™å…¥æ—¶é—´ï¼‰====
csv_last_ts = pd.to_datetime(df["date"], errors="coerce").max()
last_file_time_la = None
try:
    mtime = os.path.getmtime("data/history.csv")
    last_file_time_la = (
        pd.to_datetime(mtime, unit="s", utc=True)
        .tz_convert("America/Los_Angeles")
        .strftime("%Y-%m-%d %H:%M:%S %Z")
    )
except Exception:
    pass

msg_left = f"CSV æœ€æ–°æ—¥æœŸï¼š**{csv_last_ts.tz_convert('UTC').date().isoformat()}**" if pd.notna(csv_last_ts) else "CSV æœ€æ–°æ—¥æœŸï¼š**æœªçŸ¥**"
msg_right = f"ï½œ æ–‡ä»¶æ›´æ–°æ—¶é—´ï¼ˆLAï¼‰ï¼š**{last_file_time_la}**" if last_file_time_la else ""
st.info(f"ğŸ•’ {msg_left} {msg_right}")

# æ¯ä¸ªè§†é¢‘æœ€æ–°ä¸€è¡Œï¼ˆæ€»è®¡ï¼‰
latest = df.sort_values("date").groupby("video_id", as_index=False).tail(1).copy()
latest = latest.sort_values("published_at", ascending=False, na_position="last")

# -------- ä¾§è¾¹ç­›é€‰ --------
with st.sidebar:
    st.header("ç­›é€‰ & å·¥å…·")

    # é¢‘é“ç­›é€‰
    channels = sorted(latest["channel_title"].dropna().unique().tolist())
    sel_channel = st.selectbox("æŒ‰é¢‘é“ç­›é€‰", ["All"] + channels, index=0, key="channel_select")

    # æŒ‡æ ‡ä¸æ¨¡å¼
    metric_label = st.selectbox("æŠ˜çº¿å›¾æŒ‡æ ‡", ["æ’­æ”¾é‡ (Views)", "ç‚¹èµæ•° (Likes)", "è¯„è®ºæ•° (Comments)"], index=0, key="metric_select")
    metric_map = {
        "æ’­æ”¾é‡ (Views)": ("views", "æ’­æ”¾é‡"),
        "ç‚¹èµæ•° (Likes)": ("likes", "ç‚¹èµæ•°"),
        "è¯„è®ºæ•° (Comments)": ("comments", "è¯„è®ºæ•°"),
    }
    metric_col, metric_cn = metric_map[metric_label]
    mode = st.radio("æ•°å€¼æ¨¡å¼", ["ç´¯è®¡", "æ¯æ—¥å¢é‡"], index=0, horizontal=True, key="mode_radio")

    # é»˜è®¤æ—¥æœŸèŒƒå›´
    min_d = df["day"].min() or date.today()
    max_d = df["day"].max() or date.today()

    picked = st.date_input("æŠ˜çº¿å›¾æ—¥æœŸèŒƒå›´", value=(min_d, max_d), key="date_range")
    start_day, end_day = coerce_date_range(picked, min_d, max_d)
    st.caption(f"å·²é€‰æ—¥æœŸï¼š{start_day} â†’ {end_day}")

    # æ’åºä¾æ®
    sort_label = st.selectbox("æ’åºä¾æ®", ["æŒ‰æ’­æ”¾é‡", "æŒ‰ç‚¹èµæ•°", "æŒ‰è¯„è®ºæ•°", "æŒ‰å‘å¸ƒæ—¥æœŸï¼ˆæ–°â†’æ—§ï¼‰"], index=3, key="sort_select")
    sort_map = {"æŒ‰æ’­æ”¾é‡": "views", "æŒ‰ç‚¹èµæ•°": "likes", "æŒ‰è¯„è®ºæ•°": "comments"}

    st.write("---")
    if st.button("ğŸ”„ åˆ·æ–°æ•°æ®ï¼ˆæ¸…ç¼“å­˜ï¼‰", key="refresh"):
        st.cache_data.clear()
        st.rerun()

# æ ¹æ®é¢‘é“ç­›é€‰
filtered_latest = latest if sel_channel == "All" else latest[latest["channel_title"] == sel_channel]

# æ’åº
if sort_label == "æŒ‰å‘å¸ƒæ—¥æœŸï¼ˆæ–°â†’æ—§ï¼‰":
    filtered_latest = filtered_latest.sort_values("published_at", ascending=False, na_position="last")
else:
    filtered_latest = filtered_latest.sort_values(sort_map[sort_label], ascending=False)

selected_ids = set(filtered_latest["video_id"])

# === ç”¨â€œè‡ªç„¶æ—¥â€åˆ—åšç»Ÿä¸€è¿‡æ»¤ ===
hist_df = df[df["video_id"].isin(selected_ids)].copy()
mask = (hist_df["day"] >= start_day) & (hist_df["day"] <= end_day)
show_df_for_chart = hist_df[mask].copy()

# å‘Šè­¦ï¼šé€‰æ‹©è¶…å‡ºæ•°æ®èŒƒå›´
data_max_day = df["day"].max()
if end_day > data_max_day:
    st.warning(f"æ‰€é€‰ç»“æŸæ—¥æœŸ **{end_day}** è¶…è¿‡å½“å‰æ•°æ®æœ€æ–°æ—¥æœŸ **{data_max_day}**ï¼Œå›¾è¡¨åªæ˜¾ç¤ºåˆ° {data_max_day}ã€‚")

st.caption(f"æ•°æ®æŒ‰å¤©è®°å½•ï¼›é¢‘é“ï¼š{sel_channel} ï½œ è§†é¢‘æ•°ï¼š{filtered_latest.shape[0]}")

# å…¨å±€ KPIï¼ˆæˆªè‡³æœ€æ–°åˆè®¡ï¼‰
kpi_scope = filtered_latest.copy()
total_views = int(kpi_scope["views"].sum())
total_likes = int(kpi_scope["likes"].sum())
total_comments = int(kpi_scope["comments"].sum())
like_rate = (total_likes / total_views * 100) if total_views > 0 else 0.0
comment_rate = (total_comments / total_views * 100) if total_views > 0 else 0.0

k1, k2, k3, k4, k5 = st.columns(5)
k1.metric("æ€»æ’­æ”¾é‡ï¼ˆæˆªè‡³æœ€æ–°ï¼‰", f"{total_views:,}")
k2.metric("æ€»ç‚¹èµæ•°ï¼ˆæˆªè‡³æœ€æ–°ï¼‰", f"{total_likes:,}")
k3.metric("æ€»è¯„è®ºæ•°ï¼ˆæˆªè‡³æœ€æ–°ï¼‰", f"{total_comments:,}")
k4.metric("Like Rateï¼ˆç‚¹èµç‡ï¼‰", f"{like_rate:.2f}%")
k5.metric("Comment Rateï¼ˆè¯„è®ºç‡ï¼‰", f"{comment_rate:.2f}%")

# ===== é¡¶éƒ¨ KPI æ±‡æ€»ï¼ˆä¸¥æ ¼æŒ‰æ‰€é€‰â€œè‡ªç„¶æ—¥åŒºé—´â€çš„åŒºé—´å¢é‡ï¼‰ =====
# åœ¨å…¨é‡å†å²ä¸Šå…ˆç®—æ¯æ—¥å¢é‡ï¼Œå†æŒ‰ day åŒºé—´æˆªå–æ±‚å’Œ
base_df = df[df["video_id"].isin(selected_ids)].sort_values(["video_id", "date"]).copy()
for col in ["views", "likes", "comments"]:
    inc_col = f"{col}_inc"
    base_df[inc_col] = base_df.groupby("video_id")[col].diff().fillna(0)
    base_df.loc[base_df[inc_col] < 0, inc_col] = 0  # é¿å…å›é€€ä¸ºè´Ÿ

interval_df = base_df[(base_df["day"] >= start_day) & (base_df["day"] <= end_day)].copy()

iv_views = int(interval_df["views_inc"].sum()) if not interval_df.empty else 0
iv_likes = int(interval_df["likes_inc"].sum()) if not interval_df.empty else 0
iv_comments = int(interval_df["comments_inc"].sum()) if not interval_df.empty else 0

i1, i2, i3 = st.columns(3)
i1.metric("æœ¬æœŸæ€»å¢é‡ Â· æ’­æ”¾é‡", f"{iv_views:,}")
i2.metric("æœ¬æœŸæ€»å¢é‡ Â· ç‚¹èµæ•°", f"{iv_likes:,}")
i3.metric("æœ¬æœŸæ€»å¢é‡ Â· è¯„è®ºæ•°", f"{iv_comments:,}")

# ====== å„è§†é¢‘å•å¡ç‰‡ + æŠ˜çº¿ ======
for _, row in filtered_latest.iterrows():
    vid = row["video_id"]
    col1, col2 = st.columns([1, 3])

    with col1:
        thumb = row.get("thumbnail_url", None)
        st.markdown("<div class='thumb-cell'>", unsafe_allow_html=True)
        if pd.notna(thumb) and thumb:
            st.image(thumb, use_container_width=True)
        st.markdown("</div>", unsafe_allow_html=True)
        if pd.notna(row.get("video_url", "")) and row["video_url"]:
            st.markdown(f"[â–¶ï¸ æ‰“å¼€è§†é¢‘]({row['video_url']})")

    with col2:
        st.subheader(f"{row['title']}")
        st.write(f"**é¢‘é“**ï¼š{row['channel_title']}")
        pub = row["published_at"]
        dcount = days_since(pub)
        pub_text = pub.tz_convert("UTC").date().isoformat() if pd.notna(pub) else "æœªçŸ¥"
        st.write(f"**å‘å¸ƒæ—¥æœŸ**ï¼š{pub_text}  ï½œ  **å·²å‘å¸ƒ**ï¼š{dcount} å¤©")
        c1, c2, c3 = st.columns(3)
        c1.metric("æ€»æ’­æ”¾é‡", f"{int(row['views']):,}")
        c2.metric("æ€»ç‚¹èµæ•°", f"{int(row['likes']):,}")
        c3.metric("æ€»è¯„è®ºæ•°", f"{int(row['comments']):,}")

        vhist = show_df_for_chart[show_df_for_chart["video_id"] == vid].sort_values("date").copy()
        if vhist.empty:
            st.info("å½“å‰æ—¥æœŸèŒƒå›´å†…æ— æ•°æ®")
            continue

        if mode == "æ¯æ—¥å¢é‡":
            vhist["value"] = vhist[metric_col].diff().fillna(0)
            vhist.loc[vhist["value"] < 0, "value"] = 0
            y_title = f"{metric_cn}ï¼ˆæ¯æ—¥å¢é‡ï¼‰"
        else:
            vhist["value"] = vhist[metric_col]
            y_title = f"{metric_cn}ï¼ˆç´¯è®¡ï¼‰"

        chart_base = alt.Chart(vhist).encode(
            x=alt.X("day:T", title="æ—¥æœŸ"),  # æ³¨æ„è¿™å„¿ï¼šç”¨ day åˆ—ç”» X è½´
            y=alt.Y("value:Q", title=y_title),
            tooltip=[
                alt.Tooltip("day:T", title="æ—¥æœŸ"),
                alt.Tooltip("value:Q", title=y_title, format=","),
            ],
        )
        st.altair_chart((chart_base.mark_line() + chart_base.mark_point(size=40) + chart_base.mark_text(dy=-8).encode(text=alt.Text("value:Q", format=","))).properties(height=220), use_container_width=True)

# ====== å¤šè§†é¢‘å¯¹æ¯”ï¼ˆä¸€å¼ å›¾ï¼‰ ======
st.write("---")
st.subheader("ğŸ“Š å¤šè§†é¢‘å¯¹æ¯”ï¼ˆåŒä¸€å¼ å›¾ï¼‰")

label_map = dict(zip(filtered_latest["video_id"], filtered_latest["title"] + " â€” " + filtered_latest["channel_title"]))
opts = [label_map[v] for v in label_map]
selected_labels = st.multiselect("é€‰æ‹©å‚ä¸å¯¹æ¯”çš„è§†é¢‘", options=opts, default=opts, key="compare_select")
compare_ids = {vid for vid, lbl in label_map.items() if lbl in selected_labels}

cmp = show_df_for_chart[show_df_for_chart["video_id"].isin(compare_ids)].copy()
if cmp.empty:
    st.info("å½“å‰ç­›é€‰ä¸‹æ²¡æœ‰å¯å¯¹æ¯”çš„æ•°æ®")
else:
    cmp = cmp.sort_values(["video_id", "date"]).copy()
    if mode == "æ¯æ—¥å¢é‡":
        cmp["value"] = cmp.groupby("video_id")[metric_col].diff().fillna(0)
        cmp.loc[cmp["value"] < 0, "value"] = 0
        y_title = f"{metric_cn}ï¼ˆæ¯æ—¥å¢é‡ï¼‰"
    else:
        cmp["value"] = cmp[metric_col]
        y_title = f"{metric_cn}ï¼ˆç´¯è®¡ï¼‰"
    cmp["label"] = cmp["video_id"].map(label_map)

    legend_sel = alt.selection_point(fields=["label"], bind="legend", toggle=True)
    base_cmp = alt.Chart(cmp).transform_filter(legend_sel).encode(
        x=alt.X("day:T", title="æ—¥æœŸ"),   # è¿™é‡Œä¹Ÿæ”¹ç”¨ day
        y=alt.Y("value:Q", title=y_title),
        color=alt.Color("label:N", title="è§†é¢‘"),
        tooltip=[
            alt.Tooltip("label:N", title="è§†é¢‘"),
            alt.Tooltip("day:T", title="æ—¥æœŸ"),
            alt.Tooltip("value:Q", title=y_title, format=","),
        ],
    ).add_params(legend_sel)

    st.altair_chart((base_cmp.mark_line() + base_cmp.mark_point(size=36) + base_cmp.mark_text(dy=-8).encode(text=alt.Text("value:Q", format=","))).properties(height=360), use_container_width=True)

st.write("---")

# ====== DEBUG é¢æ¿ï¼šå¦‚æœâ€œé¡µé¢ä¸å˜â€ï¼Œè¿™é‡Œèƒ½ä¸€çœ¼çœ‹å‡ºé—®é¢˜ ======
with st.expander("ğŸ”§ DEBUGï¼ˆæ’æŸ¥ç”¨ï¼Œç¨³å®šåå¯åˆ é™¤ï¼‰", expanded=False):
    st.write("åŸå§‹æ•°æ®æœ€æ—©/æœ€æ™šä¸€è¡Œï¼š", df["date"].min(), "â†’", df["date"].max())
    st.write("åŸå§‹ day èŒƒå›´ï¼š", df["day"].min(), "â†’", df["day"].max())
    st.write("å·²é€‰ day èŒƒå›´ï¼š", start_day, "â†’", end_day)
    st.write("è¿‡æ»¤å‰è¡Œæ•°ï¼š", hist_df.shape[0], "ï¼›è¿‡æ»¤åè¡Œæ•°ï¼š", show_df_for_chart.shape[0])
    st.dataframe(show_df_for_chart.head(10), use_container_width=True)

st.caption("æ•°æ®æ¥æºï¼šdata/history.csvï¼ˆç”±å®šæ—¶ä»»åŠ¡æ›´æ–°ï¼‰ã€‚æ—¶åŒºï¼šAmerica/Los_Angelesã€‚")
